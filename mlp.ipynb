{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "32898664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aa148476",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla = yf.Ticker(\"tsla\")\n",
    "\n",
    "tsla_hist = tsla.history(period='5y', interval='1d', end='2025-06-13')\n",
    "# tsla_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "61b36e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla_hist.drop(columns=['Dividends', 'Stock Splits'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6e3f8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla_hist.index =pd.to_numeric(tsla_hist.index)\n",
    "tsla_hist.index = tsla_hist.index/(max(tsla_hist.index)) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4f0799a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tsla_hist.columns:\n",
    "    tsla_hist[col] = tsla_hist[col]/max(tsla_hist[col]) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "190d232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tsla_hist.drop(columns=['Close'])\n",
    "y = tsla_hist['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3f8e18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Date'] = X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3ba02489",
   "metadata": {},
   "outputs": [],
   "source": [
    "for delay in range(1,4):\n",
    "    X[f\"Delay {delay}\"] = y.iloc[(3-delay):-(delay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0bbb3c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = [[d, h, l, o, vol, v1, v2, v3] for d, h, l, o, vol, v1, v2, v3 in zip(X['Date'].iloc[3:].values, X['High'].iloc[3:].values, X['Low'].iloc[3:].values,X['Open'].iloc[3:].values, X['Volume'].iloc[3:].values, X['Delay 1'].dropna().values, X['Delay 2'].dropna().values, X['Delay 3'].dropna().values)]\n",
    "y_sample = y.iloc[3:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d7e29845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1252, 1252)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X['Date'].iloc[3:].values), len(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "934a728f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1252, 1252)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_sample), len(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9cf23983",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "33265382",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(np.array(X))\n",
    "y = torch.from_numpy(np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e53489db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e3b9c7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7c6221ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(X,y) for X, y in zip(X[:-273], y[:-273])]\n",
    "test_data = [(X,y) for X, y in zip(X[-273:], y[-273:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "266a8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32,)\n",
    "test_dataloader= DataLoader(test_data, batch_size=32,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e9a33041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found on batch: 0\n",
      "tensor([[1.1401, 1.1377, 1.1443, 1.1432, 1.9101,    nan,    nan, 1.1381],\n",
      "        [1.1399, 1.1381, 1.1448, 1.1433, 1.9101,    nan, 1.1392, 1.1392],\n",
      "        [1.1393, 1.1366, 1.1389, 1.2467, 1.9102, 1.1335, 1.1335, 1.1335],\n",
      "        [1.1337, 1.1345, 1.1366, 1.2083, 1.9102, 1.1370, 1.1370, 1.1370],\n",
      "        [1.1394, 1.1358, 1.1391, 1.1993, 1.9103, 1.1333, 1.1333, 1.1333],\n",
      "        [1.1357, 1.1378, 1.1382, 1.2032, 1.9104, 1.1402, 1.1402, 1.1402],\n",
      "        [1.1410, 1.1484, 1.1463, 1.3808, 1.9105, 1.1500, 1.1500, 1.1500],\n",
      "        [1.1517, 1.1549, 1.1574, 1.3000, 1.9105, 1.1555, 1.1555, 1.1555],\n",
      "        [1.1711, 1.1676, 1.1728, 1.3883, 1.9106, 1.1679, 1.1679, 1.1679],\n",
      "        [1.1788, 1.1880, 1.1845, 1.4630, 1.9107, 1.1906, 1.1906, 1.1906],\n",
      "        [1.1968, 1.1951, 1.1948, 1.4837, 1.9108, 1.1931, 1.1931, 1.1931],\n",
      "        [1.1968, 1.1934, 1.1911, 1.3672, 1.9108, 1.1898, 1.1898, 1.1898],\n",
      "        [1.1957, 1.1922, 1.1969, 1.2638, 1.9109, 1.1937, 1.1937, 1.1937],\n",
      "        [1.1956, 1.2114, 1.2005, 1.5253, 1.9109, 1.2146, 1.2146, 1.2146],\n",
      "        [1.2324, 1.2449, 1.2144, 1.8776, 1.9111, 1.2080, 1.2080, 1.2080],\n",
      "        [1.2180, 1.2170, 1.2085, 1.5271, 1.9111, 1.2107, 1.2107, 1.2107],\n",
      "        [1.2162, 1.2115, 1.2123, 1.3684, 1.9112, 1.2148, 1.2148, 1.2148],\n",
      "        [1.2069, 1.2090, 1.2136, 1.3219, 1.9112, 1.2085, 1.2085, 1.2085],\n",
      "        [1.2120, 1.2098, 1.2171, 1.2100, 1.9113, 1.2085, 1.2085, 1.2085],\n",
      "        [1.2128, 1.2252, 1.2168, 1.3854, 1.9114, 1.2283, 1.2283, 1.2283],\n",
      "        [1.2297, 1.2286, 1.2270, 1.3626, 1.9115, 1.2179, 1.2179, 1.2179],\n",
      "        [1.2240, 1.2219, 1.2276, 1.3188, 1.9115, 1.2212, 1.2212, 1.2212],\n",
      "        [1.2352, 1.2305, 1.2158, 1.5476, 1.9116, 1.2102, 1.2102, 1.2102],\n",
      "        [1.1984, 1.1999, 1.1991, 1.4366, 1.9116, 1.1969, 1.1969, 1.1969],\n",
      "        [1.2010, 1.2112, 1.2059, 1.3613, 1.9118, 1.2139, 1.2139, 1.2139],\n",
      "        [1.2107, 1.2135, 1.2148, 1.3558, 1.9118, 1.2051, 1.2051, 1.2051],\n",
      "        [1.2103, 1.2094, 1.2167, 1.2122, 1.9119, 1.2083, 1.2083, 1.2083],\n",
      "        [1.2084, 1.2065, 1.2143, 1.1715, 1.9119, 1.2067, 1.2067, 1.2067],\n",
      "        [1.2122, 1.2070, 1.2071, 1.2748, 1.9120, 1.1988, 1.1988, 1.1988],\n",
      "        [1.2030, 1.2060, 1.2105, 1.1983, 1.9121, 1.2063, 1.2063, 1.2063],\n",
      "        [1.2094, 1.2084, 1.2130, 1.1894, 1.9122, 1.2066, 1.2066, 1.2066],\n",
      "        [1.2091, 1.2047, 1.2140, 1.1114, 1.9122, 1.2063, 1.2063, 1.2063]])\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "batch = 0\n",
    "for (X, y) in train_dataloader:\n",
    "    if (torch.any(X.isnan())):\n",
    "        print(f\"Found on batch: {batch}\")\n",
    "        print(X)\n",
    "        count+=1\n",
    "    batch +=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3c092330",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, output_features):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(input_features, hidden_features),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Linear(hidden_features, 15),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l3 = nn.Linear(15, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        x = self.l3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d68cb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpmodel = MLP(8, 30, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3b7d0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=mlpmodel.parameters(), lr=1.e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "943158f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We're on batch: 0 + Loss: nan\n",
      "We're on batch: 1 + Loss: nan\n",
      "We're on batch: 2 + Loss: nan\n",
      "We're on batch: 3 + Loss: nan\n",
      "We're on batch: 4 + Loss: nan\n",
      "We're on batch: 5 + Loss: nan\n",
      "We're on batch: 6 + Loss: nan\n",
      "We're on batch: 7 + Loss: nan\n",
      "We're on batch: 8 + Loss: nan\n",
      "We're on batch: 9 + Loss: nan\n",
      "We're on batch: 10 + Loss: nan\n",
      "We're on batch: 11 + Loss: nan\n",
      "We're on batch: 12 + Loss: nan\n",
      "We're on batch: 13 + Loss: nan\n",
      "We're on batch: 14 + Loss: nan\n",
      "We're on batch: 15 + Loss: nan\n",
      "We're on batch: 16 + Loss: nan\n",
      "We're on batch: 17 + Loss: nan\n",
      "We're on batch: 18 + Loss: nan\n",
      "We're on batch: 19 + Loss: nan\n",
      "We're on batch: 20 + Loss: nan\n",
      "We're on batch: 21 + Loss: nan\n",
      "We're on batch: 22 + Loss: nan\n",
      "We're on batch: 23 + Loss: nan\n",
      "We're on batch: 24 + Loss: nan\n",
      "We're on batch: 25 + Loss: nan\n",
      "We're on batch: 26 + Loss: nan\n",
      "We're on batch: 27 + Loss: nan\n",
      "We're on batch: 28 + Loss: nan\n",
      "We're on batch: 29 + Loss: nan\n",
      "We're on batch: 30 + Loss: nan\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "mlpmodel.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        preds = mlpmodel(X)\n",
    "        # print(f\"Preds + {preds}\")\n",
    "        loss = loss_fn(torch.unsqueeze(y, 1), preds)\n",
    "        total_loss+= loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"We're on batch: {batch} + Loss: {total_loss/batch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949d848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
