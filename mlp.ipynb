{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "32898664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aa148476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-19 00:00:00-04:00</th>\n",
       "      <td>67.518669</td>\n",
       "      <td>67.731331</td>\n",
       "      <td>66.089333</td>\n",
       "      <td>66.726669</td>\n",
       "      <td>130195500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-22 00:00:00-04:00</th>\n",
       "      <td>66.663330</td>\n",
       "      <td>67.258667</td>\n",
       "      <td>66.001335</td>\n",
       "      <td>66.288002</td>\n",
       "      <td>95436000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-23 00:00:00-04:00</th>\n",
       "      <td>66.592003</td>\n",
       "      <td>67.466667</td>\n",
       "      <td>66.267334</td>\n",
       "      <td>66.785332</td>\n",
       "      <td>95479500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-24 00:00:00-04:00</th>\n",
       "      <td>66.274002</td>\n",
       "      <td>66.725334</td>\n",
       "      <td>63.542667</td>\n",
       "      <td>64.056664</td>\n",
       "      <td>164394000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-25 00:00:00-04:00</th>\n",
       "      <td>63.618000</td>\n",
       "      <td>65.732002</td>\n",
       "      <td>62.476665</td>\n",
       "      <td>65.732002</td>\n",
       "      <td>138817500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-11 00:00:00-04:00</th>\n",
       "      <td>334.399994</td>\n",
       "      <td>335.500000</td>\n",
       "      <td>322.500000</td>\n",
       "      <td>326.429993</td>\n",
       "      <td>122611400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-12 00:00:00-04:00</th>\n",
       "      <td>323.079987</td>\n",
       "      <td>332.559998</td>\n",
       "      <td>316.859985</td>\n",
       "      <td>319.109985</td>\n",
       "      <td>105127500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-13 00:00:00-04:00</th>\n",
       "      <td>313.970001</td>\n",
       "      <td>332.989990</td>\n",
       "      <td>313.299988</td>\n",
       "      <td>325.309998</td>\n",
       "      <td>128964300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-16 00:00:00-04:00</th>\n",
       "      <td>331.290009</td>\n",
       "      <td>332.049988</td>\n",
       "      <td>326.410004</td>\n",
       "      <td>329.130005</td>\n",
       "      <td>83925900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-06-17 00:00:00-04:00</th>\n",
       "      <td>326.089996</td>\n",
       "      <td>327.260010</td>\n",
       "      <td>314.739990</td>\n",
       "      <td>316.350006</td>\n",
       "      <td>88282700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Date                                                                        \n",
       "2020-06-19 00:00:00-04:00   67.518669   67.731331   66.089333   66.726669   \n",
       "2020-06-22 00:00:00-04:00   66.663330   67.258667   66.001335   66.288002   \n",
       "2020-06-23 00:00:00-04:00   66.592003   67.466667   66.267334   66.785332   \n",
       "2020-06-24 00:00:00-04:00   66.274002   66.725334   63.542667   64.056664   \n",
       "2020-06-25 00:00:00-04:00   63.618000   65.732002   62.476665   65.732002   \n",
       "...                               ...         ...         ...         ...   \n",
       "2025-06-11 00:00:00-04:00  334.399994  335.500000  322.500000  326.429993   \n",
       "2025-06-12 00:00:00-04:00  323.079987  332.559998  316.859985  319.109985   \n",
       "2025-06-13 00:00:00-04:00  313.970001  332.989990  313.299988  325.309998   \n",
       "2025-06-16 00:00:00-04:00  331.290009  332.049988  326.410004  329.130005   \n",
       "2025-06-17 00:00:00-04:00  326.089996  327.260010  314.739990  316.350006   \n",
       "\n",
       "                              Volume  Dividends  Stock Splits  \n",
       "Date                                                           \n",
       "2020-06-19 00:00:00-04:00  130195500        0.0           0.0  \n",
       "2020-06-22 00:00:00-04:00   95436000        0.0           0.0  \n",
       "2020-06-23 00:00:00-04:00   95479500        0.0           0.0  \n",
       "2020-06-24 00:00:00-04:00  164394000        0.0           0.0  \n",
       "2020-06-25 00:00:00-04:00  138817500        0.0           0.0  \n",
       "...                              ...        ...           ...  \n",
       "2025-06-11 00:00:00-04:00  122611400        0.0           0.0  \n",
       "2025-06-12 00:00:00-04:00  105127500        0.0           0.0  \n",
       "2025-06-13 00:00:00-04:00  128964300        0.0           0.0  \n",
       "2025-06-16 00:00:00-04:00   83925900        0.0           0.0  \n",
       "2025-06-17 00:00:00-04:00   88282700        0.0           0.0  \n",
       "\n",
       "[1255 rows x 7 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsla = yf.Ticker(\"tsla\")\n",
    "\n",
    "tsla_hist = tsla.history(period='5y', interval='1d', end='2025-06-13')\n",
    "tsla_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "61b36e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla_hist.drop(columns=['Dividends', 'Stock Splits'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "6e3f8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsla_hist.index =pd.to_numeric(tsla_hist.index)\n",
    "tsla_hist.index = tsla_hist.index/(max(tsla_hist.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4f0799a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tsla_hist.columns:\n",
    "    tsla_hist[col] = tsla_hist[col]/max(tsla_hist[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "190d232b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tsla_hist.drop(columns=['Close'])\n",
    "y = tsla_hist['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3f8e18b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X['Date'] = X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "87a9a33d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;PCA<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.decomposition.PCA.html\">?<span>Documentation for PCA</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>PCA(n_components=5)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=5)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=5)\n",
    "\n",
    "pca.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "673bf3f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(X.columns, pca.explained_variance_)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('PCA Importance')\n",
    "plt.title(\"PCA Decompostion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3ba02489",
   "metadata": {},
   "outputs": [],
   "source": [
    "for delay in range(1,4):\n",
    "    X[f\"Delay {delay}\"] = y.iloc[(3-delay):-(delay)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "39c2ae6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Date</th>\n",
       "      <th>Delay 1</th>\n",
       "      <th>Delay 2</th>\n",
       "      <th>Delay 3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.909953</th>\n",
       "      <td>0.141876</td>\n",
       "      <td>0.138640</td>\n",
       "      <td>0.144454</td>\n",
       "      <td>0.195378</td>\n",
       "      <td>0.909953</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.139054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.910101</th>\n",
       "      <td>0.140078</td>\n",
       "      <td>0.137673</td>\n",
       "      <td>0.144262</td>\n",
       "      <td>0.143216</td>\n",
       "      <td>0.910101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138140</td>\n",
       "      <td>0.138140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.910151</th>\n",
       "      <td>0.139929</td>\n",
       "      <td>0.138099</td>\n",
       "      <td>0.144843</td>\n",
       "      <td>0.143281</td>\n",
       "      <td>0.910151</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>0.139177</td>\n",
       "      <td>0.139177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.910200</th>\n",
       "      <td>0.139260</td>\n",
       "      <td>0.136581</td>\n",
       "      <td>0.138888</td>\n",
       "      <td>0.246698</td>\n",
       "      <td>0.910200</td>\n",
       "      <td>0.133490</td>\n",
       "      <td>0.133490</td>\n",
       "      <td>0.133490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.910250</th>\n",
       "      <td>0.133679</td>\n",
       "      <td>0.134548</td>\n",
       "      <td>0.136558</td>\n",
       "      <td>0.208316</td>\n",
       "      <td>0.910250</td>\n",
       "      <td>0.136982</td>\n",
       "      <td>0.136982</td>\n",
       "      <td>0.136982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999704</th>\n",
       "      <td>0.702669</td>\n",
       "      <td>0.686740</td>\n",
       "      <td>0.704903</td>\n",
       "      <td>0.183997</td>\n",
       "      <td>0.999704</td>\n",
       "      <td>0.680261</td>\n",
       "      <td>0.680261</td>\n",
       "      <td>0.680261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999753</th>\n",
       "      <td>0.678882</td>\n",
       "      <td>0.680722</td>\n",
       "      <td>0.692575</td>\n",
       "      <td>0.157759</td>\n",
       "      <td>0.999753</td>\n",
       "      <td>0.665006</td>\n",
       "      <td>0.665006</td>\n",
       "      <td>0.665006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999803</th>\n",
       "      <td>0.659739</td>\n",
       "      <td>0.681602</td>\n",
       "      <td>0.684794</td>\n",
       "      <td>0.193530</td>\n",
       "      <td>0.999803</td>\n",
       "      <td>0.677927</td>\n",
       "      <td>0.677927</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.999951</th>\n",
       "      <td>0.696134</td>\n",
       "      <td>0.679678</td>\n",
       "      <td>0.713449</td>\n",
       "      <td>0.125943</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.685888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.000000</th>\n",
       "      <td>0.685207</td>\n",
       "      <td>0.669874</td>\n",
       "      <td>0.687941</td>\n",
       "      <td>0.132481</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1255 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open      High       Low    Volume      Date   Delay 1  \\\n",
       "Date                                                                   \n",
       "0.909953  0.141876  0.138640  0.144454  0.195378  0.909953       NaN   \n",
       "0.910101  0.140078  0.137673  0.144262  0.143216  0.910101       NaN   \n",
       "0.910151  0.139929  0.138099  0.144843  0.143281  0.910151  0.139177   \n",
       "0.910200  0.139260  0.136581  0.138888  0.246698  0.910200  0.133490   \n",
       "0.910250  0.133679  0.134548  0.136558  0.208316  0.910250  0.136982   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "0.999704  0.702669  0.686740  0.704903  0.183997  0.999704  0.680261   \n",
       "0.999753  0.678882  0.680722  0.692575  0.157759  0.999753  0.665006   \n",
       "0.999803  0.659739  0.681602  0.684794  0.193530  0.999803  0.677927   \n",
       "0.999951  0.696134  0.679678  0.713449  0.125943  0.999951  0.685888   \n",
       "1.000000  0.685207  0.669874  0.687941  0.132481  1.000000       NaN   \n",
       "\n",
       "           Delay 2   Delay 3  \n",
       "Date                          \n",
       "0.909953       NaN  0.139054  \n",
       "0.910101  0.138140  0.138140  \n",
       "0.910151  0.139177  0.139177  \n",
       "0.910200  0.133490  0.133490  \n",
       "0.910250  0.136982  0.136982  \n",
       "...            ...       ...  \n",
       "0.999704  0.680261  0.680261  \n",
       "0.999753  0.665006  0.665006  \n",
       "0.999803  0.677927       NaN  \n",
       "0.999951       NaN       NaN  \n",
       "1.000000       NaN       NaN  \n",
       "\n",
       "[1255 rows x 8 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0bbb3c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = [[d, h, l, o, vol, v1, v2, v3] for d, h, l, o, vol, v1, v2, v3 in zip(X['Date'].iloc[3:].values, X['High'].iloc[3:].values, X['Low'].iloc[3:].values,X['Open'].iloc[3:].values, X['Volume'].iloc[3:].values, X['Delay 1'].dropna().values, X['Delay 2'].dropna().values, X['Delay 3'].dropna().values)]\n",
    "y_sample = y.iloc[3:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d7e29845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1252, 1252)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X['Date'].iloc[3:].values), len(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "934a728f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1252, 1252)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_sample), len(X_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9cf23983",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "33265382",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(np.array(X))\n",
    "y = torch.from_numpy(np.array(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "e53489db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e3b9c7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "7c6221ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = [(X,y) for X, y in zip(X[:-273], y[:-273])]\n",
    "test_data = [(X,y) for X, y in zip(X[-273:], y[-273:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "266a8097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_dataloaader= DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3c092330",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, output_features):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.Sequential(\n",
    "            nn.Linear(in_features=input_features,out_features=hidden_features),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l2 = nn.Sequential(\n",
    "            nn.Linear(in_features=hidden_features, out_features=15),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.l3 = nn.Linear(in_features=15, out_features=output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.l1(x)\n",
    "        x = self.l2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d68cb6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlpmodel = MLP(8, 15, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3b7d0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=mlpmodel.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "943158f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preds + tensor([[0.0000, 0.0000, 0.1916, 0.0747, 0.0000, 0.0000, 0.0000, 0.0000, 0.4684,\n",
      "         0.0000, 0.0000, 0.1208, 0.3145, 0.3356, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2038, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.3728,\n",
      "         0.0000, 0.0000, 0.1189, 0.2913, 0.3075, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2302, 0.0382, 0.0000, 0.0000, 0.0000, 0.0000, 0.2609,\n",
      "         0.0479, 0.0000, 0.1009, 0.2662, 0.2896, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2516, 0.0539, 0.0000, 0.0000, 0.0000, 0.0000, 0.2863,\n",
      "         0.0397, 0.0000, 0.0854, 0.2747, 0.3083, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1995, 0.0582, 0.0000, 0.0000, 0.0000, 0.0000, 0.3876,\n",
      "         0.0000, 0.0000, 0.1282, 0.2941, 0.3085, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1902, 0.0647, 0.0000, 0.0000, 0.0000, 0.0000, 0.4341,\n",
      "         0.0000, 0.0000, 0.1287, 0.3057, 0.3187, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1869, 0.0632, 0.0000, 0.0000, 0.0000, 0.0000, 0.4315,\n",
      "         0.0000, 0.0000, 0.1315, 0.3043, 0.3158, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2239, 0.0786, 0.0000, 0.0000, 0.0000, 0.0000, 0.4386,\n",
      "         0.0000, 0.0000, 0.0886, 0.3121, 0.3456, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1815, 0.0727, 0.0000, 0.0000, 0.0000, 0.0000, 0.5223,\n",
      "         0.0000, 0.0000, 0.1337, 0.3319, 0.3439, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2187, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.3363,\n",
      "         0.0000, 0.0000, 0.1141, 0.2829, 0.3044, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1959, 0.0577, 0.0000, 0.0000, 0.0000, 0.0000, 0.3957,\n",
      "         0.0000, 0.0000, 0.1238, 0.2963, 0.3105, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2296, 0.0624, 0.0000, 0.0000, 0.0000, 0.0000, 0.3528,\n",
      "         0.0000, 0.0000, 0.1030, 0.2892, 0.3170, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2233, 0.0536, 0.0000, 0.0000, 0.0000, 0.0000, 0.3349,\n",
      "         0.0000, 0.0000, 0.1007, 0.2847, 0.3102, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1897, 0.0760, 0.0000, 0.0000, 0.0000, 0.0000, 0.5016,\n",
      "         0.0000, 0.0000, 0.1267, 0.3246, 0.3387, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1973, 0.0585, 0.0000, 0.0000, 0.0000, 0.0000, 0.3968,\n",
      "         0.0000, 0.0000, 0.1225, 0.2969, 0.3121, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2097, 0.0584, 0.0000, 0.0000, 0.0000, 0.0000, 0.3760,\n",
      "         0.0000, 0.0000, 0.1112, 0.2933, 0.3150, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2188, 0.0594, 0.0000, 0.0000, 0.0000, 0.0000, 0.3563,\n",
      "         0.0000, 0.0000, 0.1172, 0.2881, 0.3083, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1906, 0.0720, 0.0000, 0.0000, 0.0000, 0.0000, 0.4698,\n",
      "         0.0000, 0.0000, 0.1285, 0.3157, 0.3301, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2084, 0.0716, 0.0000, 0.0000, 0.0000, 0.0000, 0.4248,\n",
      "         0.0000, 0.0000, 0.1176, 0.3049, 0.3248, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2318, 0.0403, 0.0000, 0.0000, 0.0000, 0.0000, 0.2670,\n",
      "         0.0454, 0.0000, 0.0985, 0.2681, 0.2928, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1807, 0.0731, 0.0000, 0.0000, 0.0000, 0.0000, 0.5209,\n",
      "         0.0000, 0.0000, 0.1326, 0.3312, 0.3446, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2168, 0.0597, 0.0000, 0.0000, 0.0000, 0.0000, 0.3617,\n",
      "         0.0000, 0.0000, 0.1142, 0.2895, 0.3100, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2210, 0.0663, 0.0000, 0.0000, 0.0000, 0.0000, 0.3801,\n",
      "         0.0000, 0.0000, 0.1068, 0.2947, 0.3203, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2342, 0.0558, 0.0000, 0.0000, 0.0000, 0.0000, 0.3189,\n",
      "         0.0017, 0.0000, 0.1014, 0.2806, 0.3069, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1807, 0.0779, 0.0000, 0.0000, 0.0000, 0.0000, 0.5332,\n",
      "         0.0000, 0.0000, 0.1280, 0.3338, 0.3526, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2120, 0.0435, 0.0000, 0.0000, 0.0000, 0.0000, 0.3114,\n",
      "         0.0000, 0.0000, 0.1146, 0.2767, 0.2946, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2324, 0.0591, 0.0000, 0.0000, 0.0000, 0.0000, 0.3332,\n",
      "         0.0000, 0.0000, 0.0996, 0.2842, 0.3132, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2566, 0.0466, 0.0000, 0.0000, 0.0000, 0.0000, 0.2553,\n",
      "         0.0736, 0.0000, 0.0757, 0.2689, 0.3047, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1870, 0.0663, 0.0000, 0.0000, 0.0000, 0.0000, 0.4489,\n",
      "         0.0000, 0.0000, 0.1323, 0.3095, 0.3234, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2041, 0.0606, 0.0000, 0.0000, 0.0000, 0.0000, 0.3924,\n",
      "         0.0000, 0.0000, 0.1221, 0.2958, 0.3120, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1934, 0.0718, 0.0000, 0.0000, 0.0000, 0.0000, 0.4594,\n",
      "         0.0000, 0.0000, 0.1267, 0.3122, 0.3265, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1912, 0.0697, 0.0000, 0.0000, 0.0000, 0.0000, 0.4605,\n",
      "         0.0000, 0.0000, 0.1303, 0.3129, 0.3256, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[0.0000, 0.0000, 0.1927, 0.0707, 0.0000, 0.0000, 0.0000, 0.0000, 0.4564,\n",
      "         0.0000, 0.0000, 0.1261, 0.3118, 0.3266, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2249, 0.0571, 0.0000, 0.0000, 0.0000, 0.0000, 0.3491,\n",
      "         0.0000, 0.0000, 0.1084, 0.2878, 0.3103, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2247, 0.0595, 0.0000, 0.0000, 0.0000, 0.0000, 0.3456,\n",
      "         0.0000, 0.0000, 0.1059, 0.2862, 0.3117, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1879, 0.0726, 0.0000, 0.0000, 0.0000, 0.0000, 0.4747,\n",
      "         0.0000, 0.0000, 0.1262, 0.3162, 0.3314, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1864, 0.0611, 0.0000, 0.0000, 0.0000, 0.0000, 0.4237,\n",
      "         0.0000, 0.0000, 0.1326, 0.3021, 0.3126, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2019, 0.0698, 0.0000, 0.0000, 0.0000, 0.0000, 0.4292,\n",
      "         0.0000, 0.0000, 0.1239, 0.3049, 0.3213, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1958, 0.0662, 0.0000, 0.0000, 0.0000, 0.0000, 0.4299,\n",
      "         0.0000, 0.0000, 0.1261, 0.3047, 0.3191, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2024, 0.0589, 0.0000, 0.0000, 0.0000, 0.0000, 0.3815,\n",
      "         0.0000, 0.0000, 0.1230, 0.2926, 0.3101, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1915, 0.0880, 0.0000, 0.0000, 0.0000, 0.0000, 0.5455,\n",
      "         0.0000, 0.0000, 0.1187, 0.3371, 0.3581, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1973, 0.0546, 0.0000, 0.0000, 0.0000, 0.0000, 0.3795,\n",
      "         0.0000, 0.0000, 0.1252, 0.2922, 0.3060, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2040, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.3894,\n",
      "         0.0000, 0.0000, 0.1168, 0.2960, 0.3132, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1841, 0.0771, 0.0000, 0.0000, 0.0000, 0.0000, 0.5062,\n",
      "         0.0000, 0.0000, 0.1246, 0.3251, 0.3449, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2113, 0.0601, 0.0000, 0.0000, 0.0000, 0.0000, 0.3794,\n",
      "         0.0000, 0.0000, 0.1076, 0.2942, 0.3171, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2442, 0.0497, 0.0000, 0.0000, 0.0000, 0.0000, 0.2739,\n",
      "         0.0455, 0.0000, 0.0932, 0.2703, 0.3011, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1986, 0.0725, 0.0000, 0.0000, 0.0000, 0.0000, 0.4620,\n",
      "         0.0000, 0.0000, 0.1235, 0.3145, 0.3303, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1946, 0.0563, 0.0000, 0.0000, 0.0000, 0.0000, 0.3900,\n",
      "         0.0000, 0.0000, 0.1262, 0.2944, 0.3079, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2163, 0.0566, 0.0000, 0.0000, 0.0000, 0.0000, 0.3479,\n",
      "         0.0000, 0.0000, 0.1200, 0.2852, 0.3034, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2032, 0.0600, 0.0000, 0.0000, 0.0000, 0.0000, 0.3866,\n",
      "         0.0000, 0.0000, 0.1229, 0.2943, 0.3120, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2031, 0.0607, 0.0000, 0.0000, 0.0000, 0.0000, 0.3903,\n",
      "         0.0000, 0.0000, 0.1195, 0.2952, 0.3141, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2112, 0.0674, 0.0000, 0.0000, 0.0000, 0.0000, 0.4012,\n",
      "         0.0000, 0.0000, 0.1186, 0.2988, 0.3184, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1997, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000, 0.4087,\n",
      "         0.0000, 0.0000, 0.1256, 0.2997, 0.3148, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1986, 0.0545, 0.0000, 0.0000, 0.0000, 0.0000, 0.3775,\n",
      "         0.0000, 0.0000, 0.1243, 0.2919, 0.3061, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2073, 0.0752, 0.0000, 0.0000, 0.0000, 0.0000, 0.4423,\n",
      "         0.0000, 0.0000, 0.1172, 0.3095, 0.3304, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2050, 0.0669, 0.0000, 0.0000, 0.0000, 0.0000, 0.4065,\n",
      "         0.0000, 0.0000, 0.1236, 0.2991, 0.3169, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1871, 0.0692, 0.0000, 0.0000, 0.0000, 0.0000, 0.4684,\n",
      "         0.0000, 0.0000, 0.1300, 0.3152, 0.3278, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2184, 0.0461, 0.0000, 0.0000, 0.0000, 0.0000, 0.3140,\n",
      "         0.0000, 0.0000, 0.1083, 0.2783, 0.2986, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2114, 0.0611, 0.0000, 0.0000, 0.0000, 0.0000, 0.3903,\n",
      "         0.0000, 0.0000, 0.1111, 0.2977, 0.3178, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1904, 0.0675, 0.0000, 0.0000, 0.0000, 0.0000, 0.4473,\n",
      "         0.0000, 0.0000, 0.1239, 0.3095, 0.3242, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1872, 0.0706, 0.0000, 0.0000, 0.0000, 0.0000, 0.4670,\n",
      "         0.0000, 0.0000, 0.1274, 0.3144, 0.3288, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2135, 0.0552, 0.0000, 0.0000, 0.0000, 0.0000, 0.3423,\n",
      "         0.0000, 0.0000, 0.1216, 0.2830, 0.3009, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2176, 0.0763, 0.0000, 0.0000, 0.0000, 0.0000, 0.4272,\n",
      "         0.0000, 0.0000, 0.1059, 0.3069, 0.3345, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2130, 0.0730, 0.0000, 0.0000, 0.0000, 0.0000, 0.4279,\n",
      "         0.0000, 0.0000, 0.1157, 0.3066, 0.3274, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[0.0000, 0.0000, 0.1880, 0.0796, 0.0000, 0.0000, 0.0000, 0.0000, 0.5318,\n",
      "         0.0000, 0.0000, 0.1267, 0.3335, 0.3482, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1923, 0.0587, 0.0000, 0.0000, 0.0000, 0.0000, 0.4069,\n",
      "         0.0000, 0.0000, 0.1288, 0.2987, 0.3105, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2261, 0.0583, 0.0000, 0.0000, 0.0000, 0.0000, 0.3380,\n",
      "         0.0000, 0.0000, 0.1117, 0.2842, 0.3073, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2025, 0.0594, 0.0000, 0.0000, 0.0000, 0.0000, 0.3958,\n",
      "         0.0000, 0.0000, 0.1181, 0.2974, 0.3141, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2048, 0.0738, 0.0000, 0.0000, 0.0000, 0.0000, 0.4375,\n",
      "         0.0000, 0.0000, 0.1196, 0.3075, 0.3273, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2064, 0.0414, 0.0000, 0.0000, 0.0000, 0.0000, 0.3110,\n",
      "         0.0000, 0.0000, 0.1200, 0.2756, 0.2904, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2071, 0.0718, 0.0000, 0.0000, 0.0000, 0.0000, 0.4283,\n",
      "         0.0000, 0.0000, 0.1196, 0.3054, 0.3244, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2001, 0.0666, 0.0000, 0.0000, 0.0000, 0.0000, 0.4284,\n",
      "         0.0000, 0.0000, 0.1198, 0.3056, 0.3224, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1894, 0.0589, 0.0000, 0.0000, 0.0000, 0.0000, 0.4092,\n",
      "         0.0000, 0.0000, 0.1307, 0.2988, 0.3103, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2247, 0.0585, 0.0000, 0.0000, 0.0000, 0.0000, 0.3458,\n",
      "         0.0000, 0.0000, 0.1074, 0.2864, 0.3101, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2077, 0.0740, 0.0000, 0.0000, 0.0000, 0.0000, 0.4385,\n",
      "         0.0000, 0.0000, 0.1176, 0.3085, 0.3281, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2042, 0.0590, 0.0000, 0.0000, 0.0000, 0.0000, 0.3871,\n",
      "         0.0000, 0.0000, 0.1157, 0.2954, 0.3147, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1890, 0.0641, 0.0000, 0.0000, 0.0000, 0.0000, 0.4330,\n",
      "         0.0000, 0.0000, 0.1294, 0.3050, 0.3169, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2232, 0.0589, 0.0000, 0.0000, 0.0000, 0.0000, 0.3462,\n",
      "         0.0000, 0.0000, 0.1144, 0.2860, 0.3074, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2506, 0.0542, 0.0000, 0.0000, 0.0000, 0.0000, 0.2954,\n",
      "         0.0413, 0.0000, 0.0773, 0.2785, 0.3141, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2469, 0.0517, 0.0000, 0.0000, 0.0000, 0.0000, 0.2802,\n",
      "         0.0417, 0.0000, 0.0912, 0.2726, 0.3038, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2134, 0.0634, 0.0000, 0.0000, 0.0000, 0.0000, 0.3778,\n",
      "         0.0000, 0.0000, 0.1179, 0.2926, 0.3128, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2123, 0.0600, 0.0000, 0.0000, 0.0000, 0.0000, 0.3799,\n",
      "         0.0000, 0.0000, 0.1157, 0.2937, 0.3130, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2026, 0.0529, 0.0000, 0.0000, 0.0000, 0.0000, 0.3571,\n",
      "         0.0000, 0.0000, 0.1269, 0.2861, 0.2999, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2070, 0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.3176,\n",
      "         0.0000, 0.0000, 0.1188, 0.2774, 0.2928, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2061, 0.0603, 0.0000, 0.0000, 0.0000, 0.0000, 0.3926,\n",
      "         0.0000, 0.0000, 0.1160, 0.2971, 0.3150, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2174, 0.0704, 0.0000, 0.0000, 0.0000, 0.0000, 0.4109,\n",
      "         0.0000, 0.0000, 0.1110, 0.3024, 0.3251, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2115, 0.0548, 0.0000, 0.0000, 0.0000, 0.0000, 0.3524,\n",
      "         0.0000, 0.0000, 0.1190, 0.2863, 0.3039, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1901, 0.0782, 0.0000, 0.0000, 0.0000, 0.0000, 0.4867,\n",
      "         0.0000, 0.0000, 0.1218, 0.3193, 0.3402, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2109, 0.0657, 0.0000, 0.0000, 0.0000, 0.0000, 0.3988,\n",
      "         0.0000, 0.0000, 0.1182, 0.2981, 0.3171, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2111, 0.0693, 0.0000, 0.0000, 0.0000, 0.0000, 0.4079,\n",
      "         0.0000, 0.0000, 0.1161, 0.3006, 0.3223, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1994, 0.0605, 0.0000, 0.0000, 0.0000, 0.0000, 0.4017,\n",
      "         0.0000, 0.0000, 0.1189, 0.2985, 0.3160, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1883, 0.0616, 0.0000, 0.0000, 0.0000, 0.0000, 0.4237,\n",
      "         0.0000, 0.0000, 0.1314, 0.3026, 0.3136, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2080, 0.0590, 0.0000, 0.0000, 0.0000, 0.0000, 0.3801,\n",
      "         0.0000, 0.0000, 0.1179, 0.2934, 0.3111, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2083, 0.0775, 0.0000, 0.0000, 0.0000, 0.0000, 0.4486,\n",
      "         0.0000, 0.0000, 0.1143, 0.3111, 0.3335, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2179, 0.0532, 0.0000, 0.0000, 0.0000, 0.0000, 0.3274,\n",
      "         0.0000, 0.0000, 0.1199, 0.2798, 0.2982, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2166, 0.0653, 0.0000, 0.0000, 0.0000, 0.0000, 0.3852,\n",
      "         0.0000, 0.0000, 0.1139, 0.2952, 0.3169, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[0.0000, 0.0000, 0.2130, 0.0549, 0.0000, 0.0000, 0.0000, 0.0000, 0.3412,\n",
      "         0.0000, 0.0000, 0.1228, 0.2828, 0.3006, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2047, 0.0552, 0.0000, 0.0000, 0.0000, 0.0000, 0.3709,\n",
      "         0.0000, 0.0000, 0.1181, 0.2911, 0.3080, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1892, 0.0712, 0.0000, 0.0000, 0.0000, 0.0000, 0.4740,\n",
      "         0.0000, 0.0000, 0.1305, 0.3173, 0.3311, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2396, 0.0611, 0.0000, 0.0000, 0.0000, 0.0000, 0.3314,\n",
      "         0.0000, 0.0000, 0.0932, 0.2848, 0.3158, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1951, 0.0694, 0.0000, 0.0000, 0.0000, 0.0000, 0.4472,\n",
      "         0.0000, 0.0000, 0.1176, 0.3100, 0.3279, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2690, 0.0608, 0.0000, 0.0000, 0.0000, 0.0000, 0.2899,\n",
      "         0.0648, 0.0000, 0.0547, 0.2792, 0.3270, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1834, 0.0771, 0.0000, 0.0000, 0.0000, 0.0000, 0.5251,\n",
      "         0.0000, 0.0000, 0.1278, 0.3315, 0.3471, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1957, 0.0651, 0.0000, 0.0000, 0.0000, 0.0000, 0.4278,\n",
      "         0.0000, 0.0000, 0.1232, 0.3047, 0.3200, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2005, 0.0613, 0.0000, 0.0000, 0.0000, 0.0000, 0.4014,\n",
      "         0.0000, 0.0000, 0.1265, 0.2979, 0.3121, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2165, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.3462,\n",
      "         0.0000, 0.0000, 0.1149, 0.2856, 0.3063, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2128, 0.0713, 0.0000, 0.0000, 0.0000, 0.0000, 0.4168,\n",
      "         0.0000, 0.0000, 0.1168, 0.3033, 0.3239, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2150, 0.0357, 0.0000, 0.0000, 0.0000, 0.0000, 0.2738,\n",
      "         0.0266, 0.0000, 0.1143, 0.2672, 0.2841, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1869, 0.0702, 0.0000, 0.0000, 0.0000, 0.0000, 0.4714,\n",
      "         0.0000, 0.0000, 0.1307, 0.3161, 0.3310, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2103, 0.0607, 0.0000, 0.0000, 0.0000, 0.0000, 0.3714,\n",
      "         0.0000, 0.0000, 0.1226, 0.2905, 0.3084, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1863, 0.0677, 0.0000, 0.0000, 0.0000, 0.0000, 0.4566,\n",
      "         0.0000, 0.0000, 0.1277, 0.3113, 0.3239, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2072, 0.0610, 0.0000, 0.0000, 0.0000, 0.0000, 0.3873,\n",
      "         0.0000, 0.0000, 0.1174, 0.2952, 0.3148, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2112, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.3669,\n",
      "         0.0000, 0.0000, 0.1141, 0.2913, 0.3100, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2246, 0.0658, 0.0000, 0.0000, 0.0000, 0.0000, 0.3723,\n",
      "         0.0000, 0.0000, 0.1059, 0.2930, 0.3195, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2019, 0.0613, 0.0000, 0.0000, 0.0000, 0.0000, 0.4039,\n",
      "         0.0000, 0.0000, 0.1187, 0.2996, 0.3161, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2076, 0.0589, 0.0000, 0.0000, 0.0000, 0.0000, 0.3884,\n",
      "         0.0000, 0.0000, 0.1146, 0.2964, 0.3144, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1978, 0.0773, 0.0000, 0.0000, 0.0000, 0.0000, 0.4834,\n",
      "         0.0000, 0.0000, 0.1193, 0.3198, 0.3371, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1964, 0.0762, 0.0000, 0.0000, 0.0000, 0.0000, 0.4779,\n",
      "         0.0000, 0.0000, 0.1196, 0.3181, 0.3370, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1986, 0.0581, 0.0000, 0.0000, 0.0000, 0.0000, 0.3915,\n",
      "         0.0000, 0.0000, 0.1219, 0.2953, 0.3109, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2593, 0.0525, 0.0000, 0.0000, 0.0000, 0.0000, 0.2670,\n",
      "         0.0598, 0.0000, 0.0795, 0.2707, 0.3071, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2139, 0.0561, 0.0000, 0.0000, 0.0000, 0.0000, 0.3453,\n",
      "         0.0000, 0.0000, 0.1207, 0.2838, 0.3023, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2258, 0.0613, 0.0000, 0.0000, 0.0000, 0.0000, 0.3561,\n",
      "         0.0000, 0.0000, 0.1057, 0.2894, 0.3143, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1991, 0.0644, 0.0000, 0.0000, 0.0000, 0.0000, 0.4118,\n",
      "         0.0000, 0.0000, 0.1220, 0.3002, 0.3173, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2208, 0.0655, 0.0000, 0.0000, 0.0000, 0.0000, 0.3774,\n",
      "         0.0000, 0.0000, 0.1097, 0.2941, 0.3177, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2050, 0.0634, 0.0000, 0.0000, 0.0000, 0.0000, 0.4092,\n",
      "         0.0000, 0.0000, 0.1200, 0.3009, 0.3181, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2382, 0.0576, 0.0000, 0.0000, 0.0000, 0.0000, 0.3254,\n",
      "         0.0005, 0.0000, 0.0950, 0.2831, 0.3121, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2018, 0.0545, 0.0000, 0.0000, 0.0000, 0.0000, 0.3741,\n",
      "         0.0000, 0.0000, 0.1213, 0.2915, 0.3066, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2195, 0.0608, 0.0000, 0.0000, 0.0000, 0.0000, 0.3593,\n",
      "         0.0000, 0.0000, 0.1149, 0.2887, 0.3096, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[0.0000, 0.0000, 0.2109, 0.0524, 0.0000, 0.0000, 0.0000, 0.0000, 0.3405,\n",
      "         0.0000, 0.0000, 0.1199, 0.2830, 0.3005, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2088, 0.0709, 0.0000, 0.0000, 0.0000, 0.0000, 0.4168,\n",
      "         0.0000, 0.0000, 0.1180, 0.3023, 0.3228, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2121, 0.0716, 0.0000, 0.0000, 0.0000, 0.0000, 0.4193,\n",
      "         0.0000, 0.0000, 0.1156, 0.3039, 0.3248, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2231, 0.0550, 0.0000, 0.0000, 0.0000, 0.0000, 0.3291,\n",
      "         0.0000, 0.0000, 0.1096, 0.2815, 0.3049, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2350, 0.0340, 0.0000, 0.0000, 0.0000, 0.0000, 0.2334,\n",
      "         0.0730, 0.0000, 0.0972, 0.2596, 0.2849, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2167, 0.0705, 0.0000, 0.0000, 0.0000, 0.0000, 0.4114,\n",
      "         0.0000, 0.0000, 0.1123, 0.3024, 0.3242, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2012, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.3772,\n",
      "         0.0000, 0.0000, 0.1215, 0.2923, 0.3081, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2134, 0.0554, 0.0000, 0.0000, 0.0000, 0.0000, 0.3461,\n",
      "         0.0000, 0.0000, 0.1230, 0.2842, 0.3012, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2077, 0.0575, 0.0000, 0.0000, 0.0000, 0.0000, 0.3815,\n",
      "         0.0000, 0.0000, 0.1154, 0.2944, 0.3120, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2484, 0.0461, 0.0000, 0.0000, 0.0000, 0.0000, 0.2641,\n",
      "         0.0621, 0.0000, 0.0817, 0.2698, 0.3029, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1928, 0.0596, 0.0000, 0.0000, 0.0000, 0.0000, 0.4095,\n",
      "         0.0000, 0.0000, 0.1287, 0.2996, 0.3119, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2203, 0.0734, 0.0000, 0.0000, 0.0000, 0.0000, 0.4130,\n",
      "         0.0000, 0.0000, 0.1064, 0.3037, 0.3300, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1908, 0.0638, 0.0000, 0.0000, 0.0000, 0.0000, 0.4298,\n",
      "         0.0000, 0.0000, 0.1290, 0.3046, 0.3168, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2211, 0.0747, 0.0000, 0.0000, 0.0000, 0.0000, 0.4193,\n",
      "         0.0000, 0.0000, 0.1046, 0.3051, 0.3311, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1937, 0.0723, 0.0000, 0.0000, 0.0000, 0.0000, 0.4663,\n",
      "         0.0000, 0.0000, 0.1272, 0.3152, 0.3303, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1987, 0.0588, 0.0000, 0.0000, 0.0000, 0.0000, 0.4022,\n",
      "         0.0000, 0.0000, 0.1218, 0.2987, 0.3132, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2155, 0.0653, 0.0000, 0.0000, 0.0000, 0.0000, 0.3837,\n",
      "         0.0000, 0.0000, 0.1156, 0.2947, 0.3167, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2084, 0.0695, 0.0000, 0.0000, 0.0000, 0.0000, 0.4141,\n",
      "         0.0000, 0.0000, 0.1165, 0.3016, 0.3226, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2207, 0.0622, 0.0000, 0.0000, 0.0000, 0.0000, 0.3650,\n",
      "         0.0000, 0.0000, 0.1104, 0.2909, 0.3139, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1821, 0.0705, 0.0000, 0.0000, 0.0000, 0.0000, 0.4964,\n",
      "         0.0000, 0.0000, 0.1327, 0.3237, 0.3374, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2082, 0.0559, 0.0000, 0.0000, 0.0000, 0.0000, 0.3672,\n",
      "         0.0000, 0.0000, 0.1142, 0.2907, 0.3111, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2179, 0.0532, 0.0000, 0.0000, 0.0000, 0.0000, 0.3309,\n",
      "         0.0000, 0.0000, 0.1159, 0.2813, 0.3007, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2217, 0.0466, 0.0000, 0.0000, 0.0000, 0.0000, 0.3114,\n",
      "         0.0040, 0.0000, 0.1057, 0.2782, 0.2998, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2016, 0.0632, 0.0000, 0.0000, 0.0000, 0.0000, 0.4081,\n",
      "         0.0000, 0.0000, 0.1141, 0.3005, 0.3216, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2135, 0.0556, 0.0000, 0.0000, 0.0000, 0.0000, 0.3606,\n",
      "         0.0000, 0.0000, 0.1079, 0.2898, 0.3111, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2337, 0.0586, 0.0000, 0.0000, 0.0000, 0.0000, 0.3329,\n",
      "         0.0000, 0.0000, 0.1012, 0.2843, 0.3108, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2041, 0.0630, 0.0000, 0.0000, 0.0000, 0.0000, 0.4016,\n",
      "         0.0000, 0.0000, 0.1200, 0.2985, 0.3160, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2091, 0.0726, 0.0000, 0.0000, 0.0000, 0.0000, 0.4305,\n",
      "         0.0000, 0.0000, 0.1170, 0.3065, 0.3261, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2288, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.3037,\n",
      "         0.0171, 0.0000, 0.0987, 0.2774, 0.3028, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2131, 0.0702, 0.0000, 0.0000, 0.0000, 0.0000, 0.4135,\n",
      "         0.0000, 0.0000, 0.1157, 0.3026, 0.3235, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2156, 0.0572, 0.0000, 0.0000, 0.0000, 0.0000, 0.3470,\n",
      "         0.0000, 0.0000, 0.1208, 0.2848, 0.3036, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1787, 0.0849, 0.0000, 0.0000, 0.0034, 0.0000, 0.5506,\n",
      "         0.0000, 0.0000, 0.1250, 0.3372, 0.3606, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[0.0000, 0.0000, 0.2114, 0.0547, 0.0000, 0.0000, 0.0000, 0.0000, 0.3445,\n",
      "         0.0000, 0.0000, 0.1253, 0.2834, 0.2994, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2099, 0.0680, 0.0000, 0.0000, 0.0000, 0.0000, 0.4104,\n",
      "         0.0000, 0.0000, 0.1185, 0.3012, 0.3199, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2064, 0.0564, 0.0000, 0.0000, 0.0000, 0.0000, 0.3649,\n",
      "         0.0000, 0.0000, 0.1227, 0.2889, 0.3055, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2190, 0.0651, 0.0000, 0.0000, 0.0000, 0.0000, 0.3757,\n",
      "         0.0000, 0.0000, 0.1109, 0.2930, 0.3171, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1904, 0.0719, 0.0000, 0.0000, 0.0000, 0.0000, 0.4658,\n",
      "         0.0000, 0.0000, 0.1285, 0.3144, 0.3304, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2284, 0.0475, 0.0000, 0.0000, 0.0000, 0.0000, 0.3034,\n",
      "         0.0164, 0.0000, 0.0988, 0.2771, 0.3022, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1983, 0.0533, 0.0000, 0.0000, 0.0000, 0.0000, 0.3745,\n",
      "         0.0000, 0.0000, 0.1252, 0.2910, 0.3041, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1822, 0.0749, 0.0000, 0.0000, 0.0000, 0.0000, 0.5255,\n",
      "         0.0000, 0.0000, 0.1308, 0.3323, 0.3456, 0.0000],\n",
      "        [   nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,    nan,\n",
      "            nan,    nan,    nan,    nan,    nan,    nan],\n",
      "        [0.0000, 0.0000, 0.1969, 0.0560, 0.0000, 0.0000, 0.0000, 0.0000, 0.3888,\n",
      "         0.0000, 0.0000, 0.1251, 0.2945, 0.3079, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2186, 0.0579, 0.0000, 0.0000, 0.0000, 0.0000, 0.3457,\n",
      "         0.0000, 0.0000, 0.1169, 0.2849, 0.3057, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1894, 0.0711, 0.0000, 0.0000, 0.0000, 0.0000, 0.4577,\n",
      "         0.0000, 0.0000, 0.1255, 0.3111, 0.3271, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1864, 0.0683, 0.0000, 0.0000, 0.0000, 0.0000, 0.4693,\n",
      "         0.0000, 0.0000, 0.1330, 0.3161, 0.3288, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2003, 0.0603, 0.0000, 0.0000, 0.0000, 0.0000, 0.3914,\n",
      "         0.0000, 0.0000, 0.1254, 0.2950, 0.3103, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2299, 0.0670, 0.0000, 0.0000, 0.0000, 0.0000, 0.3694,\n",
      "         0.0000, 0.0000, 0.0976, 0.2933, 0.3229, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1831, 0.0792, 0.0000, 0.0000, 0.0000, 0.0000, 0.5390,\n",
      "         0.0000, 0.0000, 0.1271, 0.3358, 0.3520, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1801, 0.0737, 0.0000, 0.0000, 0.0000, 0.0000, 0.5227,\n",
      "         0.0000, 0.0000, 0.1312, 0.3312, 0.3448, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2130, 0.0552, 0.0000, 0.0000, 0.0000, 0.0000, 0.3439,\n",
      "         0.0000, 0.0000, 0.1235, 0.2837, 0.3012, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2142, 0.0550, 0.0000, 0.0000, 0.0000, 0.0000, 0.3418,\n",
      "         0.0000, 0.0000, 0.1229, 0.2831, 0.3000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1971, 0.0623, 0.0000, 0.0000, 0.0000, 0.0000, 0.4122,\n",
      "         0.0000, 0.0000, 0.1229, 0.3007, 0.3161, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2282, 0.0651, 0.0000, 0.0000, 0.0000, 0.0000, 0.3634,\n",
      "         0.0000, 0.0000, 0.1011, 0.2917, 0.3204, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2156, 0.0725, 0.0000, 0.0000, 0.0000, 0.0000, 0.4129,\n",
      "         0.0000, 0.0000, 0.1118, 0.3024, 0.3259, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1859, 0.0830, 0.0000, 0.0000, 0.0000, 0.0000, 0.5437,\n",
      "         0.0000, 0.0000, 0.1246, 0.3370, 0.3557, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2051, 0.0617, 0.0000, 0.0000, 0.0000, 0.0000, 0.3929,\n",
      "         0.0000, 0.0000, 0.1220, 0.2965, 0.3142, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2231, 0.0572, 0.0000, 0.0000, 0.0000, 0.0000, 0.3365,\n",
      "         0.0000, 0.0000, 0.1145, 0.2831, 0.3046, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2236, 0.0561, 0.0000, 0.0000, 0.0000, 0.0000, 0.3364,\n",
      "         0.0000, 0.0000, 0.1104, 0.2837, 0.3059, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2009, 0.0586, 0.0000, 0.0000, 0.0000, 0.0000, 0.3944,\n",
      "         0.0000, 0.0000, 0.1202, 0.2969, 0.3125, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2130, 0.0665, 0.0000, 0.0000, 0.0000, 0.0000, 0.3933,\n",
      "         0.0000, 0.0000, 0.1174, 0.2968, 0.3167, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2568, 0.0480, 0.0000, 0.0000, 0.0000, 0.0000, 0.2612,\n",
      "         0.0697, 0.0000, 0.0746, 0.2705, 0.3068, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1898, 0.0702, 0.0000, 0.0000, 0.0000, 0.0000, 0.4594,\n",
      "         0.0000, 0.0000, 0.1285, 0.3124, 0.3269, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1895, 0.0677, 0.0000, 0.0000, 0.0000, 0.0000, 0.4500,\n",
      "         0.0000, 0.0000, 0.1305, 0.3093, 0.3219, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2344, 0.0654, 0.0000, 0.0000, 0.0000, 0.0000, 0.3554,\n",
      "         0.0000, 0.0000, 0.0944, 0.2903, 0.3215, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n",
      "Preds + tensor([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
      "        [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahul\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([32, 15])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "c:\\Users\\rahul\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:608: UserWarning: Using a target size (torch.Size([22, 15])) that is different to the input size (torch.Size([22, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "mlpmodel.train()\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        preds = mlpmodel(X)\n",
    "        print(f\"Preds + {preds}\")\n",
    "        loss = loss_fn(torch.unsqueeze(y, 1), preds)\n",
    "        total_loss+= loss\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print(f\"We're on batch: {batch} + Loss: {total_loss/batch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1949d848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
